{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import\n",
    "\"\"\"\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm, TwoSlopeNorm\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.lines as mlines\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from datetime import datetime,timedelta\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "import cartopy.crs as ccrs  # Import cartopy ccrs\n",
    "import cartopy.feature as cfeature  # Import cartopy common features\n",
    "from matplotlib import animation\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats\n",
    "import math\n",
    "import time as time_mod\n",
    "sys.path.insert(0, \"/home/chalifour/code/master\")\n",
    "from fct_script.func_py import get_proj_extent\n",
    "import fct_script.rpn_funcs_chris as rpn_chris\n",
    "from fct_script.get_domain import get_domain_info\n",
    "from fct_script.func_py import get_colormap_precip,categorical_cmap\n",
    "from matplotlib.patches import Patch\n",
    "# from func_py import get_proj_extent\n",
    "\n",
    "try:\n",
    "    import rpnpy.librmn.all as rmn  # Module to read RPN files\n",
    "    from rotated_lat_lon import RotatedLatLon  # Module to project field on native grid (created by Sasha Huziy)\n",
    "except ImportError as err:\n",
    "    print(f\"RPNPY can only be use on the server. It can't be use on a personal computer.\"\n",
    "          f\"\\nError throw :{err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "263.0 47.5 353.0 0.0\n"
     ]
    }
   ],
   "source": [
    "m, lonE2p5, latE2p5 = get_proj_extent()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "# Time array\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "begin,end = '2021-10','2022-06'\n",
    "begin_date,end_date  = datetime.strptime(begin, '%Y-%m'),datetime.strptime(end, '%Y-%m')\n",
    "\n",
    "timerange_month = pd.date_range(begin,end,freq='MS')\n",
    "timerange_day = pd.date_range(begin,end,freq='D')\n",
    "\n",
    "\n",
    "season = ['ON','DJF','MAM']\n",
    "season_dict= {'ON':{'month':[10,11],'year':begin_date.year},\n",
    "              'DJF':{'month':[12,1,2],'year':begin_date.year},\n",
    "              'MAM':{'month':[3,4,5],'year':end_date.year}}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "---\n",
    "---\n",
    "# Important path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# ON\n",
    "path_daymet_tt_on= sorted(glob.glob(\n",
    "            fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/ta*/lc/nc4/{begin_date.year}/*1[0-1]/daymet_1km_v4r1_tavg_lc_{begin_date.year}*1[0-1]_d.nc4'))\n",
    "path_daymet_pr_on = sorted(glob.glob(\n",
    "            fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/prcp/lc/nc4/{begin_date.year}/*1[0-1]/daymet_1km_v4r1_prcp_lc_{begin_date.year}*1[0-1]_d.nc4'))\n",
    "\n",
    "# path_sim_11km_on = sorted(glob.glob(fr'/BIG1/roberge/Output/GEM5/Cascades_CORDEX/CLASS/Safe_versions/Spinup/NAM-11m_ERA5_GEM5_CLASS_NV_NA_newP3-SCPF_SN8_20yrs/Samples/NAM-11m_ERA5_GEM5_CLASS_NV_NA_newP3-SCPF_SN8_20yrs_{begin_date.year}*1[0-1]'))\n",
    "path_sim_11km_on = sorted(glob.glob(fr'/chinook/roberge/Output/GEM5/Olivier/NAM-11m_ERA5_GEM50_PCPTYPEnil/Samples/NAM-11m_ERA5_GEM50_PCPTYPEnil_{begin_date.year}*1[0-1]'))\n",
    "\n",
    "# path_sim_2p5km_on = sorted(glob.glob(fr'/pampa/roberge/Output/GEM5/Cascades_CORDEX/CLASS/Safe_versions/Spinup/ECan_2.5km_NAM11mP3_newP3_CLASS_DEEPoff_SHALon/Samples/ECan_2.5km_NAM11mP3_newP3_CLASS_DEEPoff_SHALon_{begin_date.year}*1[0-1]'))\n",
    "path_sim_2p5km_on = sorted(glob.glob(fr'/chinook/roberge/Output/GEM5/Olivier/ECan_2.5km_NAM11mP3_GEM50_PCPTYPEnil/Samples/ECan_2.5km_NAM11mP3_GEM50_PCPTYPEnil_{begin_date.year}*1[0-1]'))\n",
    "\n",
    "\n",
    "\n",
    "# DJF\n",
    "# path_daymet_tt_djf= sorted(glob.glob(\n",
    "#             fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/ta*/lc/nc4/{begin_date.year}/12/daymet_1km_v4r1_ta*_lc_{begin_date.year}12_d.nc4') + glob.glob(\n",
    "#             fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/ta*/lc/nc4/{end_date.year}/0*[1-2]/daymet_1km_v4r1_ta*_lc_{end_date.year}0*[1-2]_d.nc4'))\n",
    "path_daymet_tt_djf= sorted(glob.glob(\n",
    "            fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/ta*/lc/nc4/{begin_date.year}/12/daymet_1km_v4r1_tavg_lc_{begin_date.year}12_d.nc4') + glob.glob(\n",
    "            fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/ta*/lc/nc4/{end_date.year}/0*[1-2]/daymet_1km_v4r1_ta*_lc_{end_date.year}0*[1-2]_d.nc4'))\n",
    "\n",
    "# path_daymet_pr_djf = sorted(glob.glob(\n",
    "#             fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/prcp/lc/nc4/{begin_date.year}/12/daymet_1km_v4r1_prcp_lc_{begin_date.year}12_d.nc4')+glob.glob(\n",
    "#             fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/prcp/lc/nc4/{end_date.year}/0*[1-2]/daymet_1km_v4r1_prcp_lc_{end_date.year}0*[1-2]_d.nc4'))\n",
    "\n",
    "path_daymet_pr_djf = sorted(glob.glob(\n",
    "            fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/prcp/lc/nc4/{begin_date.year}/12/daymet_1km_v4r1_prcp_lc_{begin_date.year}12_d.nc4')+glob.glob(\n",
    "            fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/prcp/lc/nc4/{end_date.year}/0*[1-2]/daymet_1km_v4r1_prcp_lc_{end_date.year}0*[1-2]_d.nc4'))\n",
    "\n",
    "# path_daymet_tt_djf= sorted(glob.glob(\n",
    "#             fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/ta*/lc/nc4/{begin_date.year}/12/daymet_1km_v4r1_ta*_lc_{begin_date.year}12_d.nc4') + glob.glob(\n",
    "#             fr'/pampa/roberge/OBSERVATIONS/Daymet_1km_v4ll/daily/ta*/lc/nc4/2022/0*[1-2]/daymet_1km_v4r1_ta*_lc_{end_date.year}0*[1-2]_d.nc4'))\n",
    "# path_daymet_pr_djf = sorted(glob.glob(\n",
    "#             fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/prcp/lc/nc4/{begin_date.year}/12/daymet_1km_v4r1_prcp_lc_{begin_date.year}12_d.nc4')+glob.glob(\n",
    "#             fr'/pampa/roberge/OBSERVATIONS/Daymet_1km_v4ll/daily/prcp/lc/nc4/2022/0*[1-2]/daymet_1km_v4r1_prcp_lc_{end_date.year}0*[1-2]_d.nc4'))\n",
    "\n",
    "\n",
    "# path_sim_11km_djf = sorted(glob.glob(fr'/BIG1/roberge/Output/GEM5/Cascades_CORDEX/CLASS/Safe_versions/Spinup/NAM-11m_ERA5_GEM5_CLASS_NV_NA_newP3-SCPF_SN8_20yrs/Samples/NAM-11m_ERA5_GEM5_CLASS_NV_NA_newP3-SCPF_SN8_20yrs_{begin_date.year}12')+glob.glob(fr'/BIG1/roberge/Output/GEM5/Cascades_CORDEX/CLASS/Safe_versions/Spinup/NAM-11m_ERA5_GEM5_CLASS_NV_NA_newP3-SCPF_SN8_20yrs/Samples/NAM-11m_ERA5_GEM5_CLASS_NV_NA_newP3-SCPF_SN8_20yrs_{end_date.year}0*[1-2]'))\n",
    "path_sim_11km_djf = sorted(glob.glob(fr'/chinook/roberge/Output/GEM5/Olivier/NAM-11m_ERA5_GEM50_PCPTYPEnil/Samples/NAM-11m_ERA5_GEM50_PCPTYPEnil_{begin_date.year}12')+glob.glob(fr'/chinook/roberge/Output/GEM5/Olivier/NAM-11m_ERA5_GEM50_PCPTYPEnil/Samples/NAM-11m_ERA5_GEM50_PCPTYPEnil_{end_date.year}0*[1-2]'))\n",
    "\n",
    "# path_sim_2p5km_djf = sorted(glob.glob(fr'/pampa/roberge/Output/GEM5/Cascades_CORDEX/CLASS/Safe_versions/Spinup/ECan_2.5km_NAM11mP3_newP3_CLASS_DEEPoff_SHALon/Samples/ECan_2.5km_NAM11mP3_newP3_CLASS_DEEPoff_SHALon_{begin_date.year}12')+glob.glob(fr'/pampa/roberge/Output/GEM5/Cascades_CORDEX/CLASS/Safe_versions/Spinup/ECan_2.5km_NAM11mP3_newP3_CLASS_DEEPoff_SHALon/Samples/ECan_2.5km_NAM11mP3_newP3_CLASS_DEEPoff_SHALon_{end_date.year}0*[1-2]'))\n",
    "path_sim_2p5km_djf = sorted(glob.glob(fr'/chinook/roberge/Output/GEM5/Olivier/ECan_2.5km_NAM11mP3_GEM50_PCPTYPEnil/Samples/ECan_2.5km_NAM11mP3_GEM50_PCPTYPEnil_{begin_date.year}12')+glob.glob(fr'/chinook/roberge/Output/GEM5/Olivier/ECan_2.5km_NAM11mP3_GEM50_PCPTYPEnil/Samples/ECan_2.5km_NAM11mP3_GEM50_PCPTYPEnil_{end_date.year}0*[1-2]'))\n",
    "\n",
    "# /pampa/roberge/OBSERVATIONS/Daymet_1km_v4ll\n",
    "# MAM\n",
    "path_daymet_tt_mam= sorted(glob.glob(\n",
    "            fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/ta*/lc/nc4/{end_date.year}/0*[3-5]/daymet_1km_v4r1_tavg_lc_{end_date.year}0*[3-5]_d.nc4'))\n",
    "path_daymet_pr_mam = sorted(glob.glob(\n",
    "            fr'/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/prcp/lc/nc4/{end_date.year}/0*[3-5]/daymet_1km_v4r1_prcp_lc_{end_date.year}0*[3-5]_d.nc4'))\n",
    "#\n",
    "# path_daymet_tt_mam= sorted(glob.glob(\n",
    "#             fr'/pampa/roberge/OBSERVATIONS/Daymet_1km_v4ll/daily/ta*/lc/nc4/{end_date.year}/0*[3-5]/daymet_1km_v4ll_ta*_lc_{end_date.year}0*[3-5]_d.nc4'))\n",
    "#\n",
    "# path_daymet_pr_mam = sorted(glob.glob(\n",
    "#             fr'/pampa/roberge/OBSERVATIONS/Daymet_1km_v4ll/daily/prcp/lc/nc4/{end_date.year}/0*[3-5]/daymet_1km_v4ll_prcp_lc_{end_date.year}0*[3-5]_d.nc4'))\n",
    "\n",
    "# path_daymet_tt_mam= sorted(glob.glob(\n",
    "#             fr'/pampa/roberge/OBSERVATIONS/Daymet_1km_v4ll/daily/ta*/lc/nc4/2022/0*[3-5]/daymet_1km_v4ll_ta*_lc_{end_date.year}0*[3-5]_d.nc4'))\n",
    "# path_daymet_pr_mam = sorted(glob.glob(\n",
    "#             fr'/pampa/roberge/OBSERVATIONS/Daymet_1km_v4ll/daily/prcp/lc/nc4/2022/0*[3-5]/daymet_1km_v4ll_prcp_lc_{end_date.year}0*[3-5]_d.nc4'))\n",
    "#\n",
    "# path_sim_11km_mam = sorted(glob.glob(fr'/BIG1/roberge/Output/GEM5/Cascades_CORDEX/CLASS/Safe_versions/Spinup/NAM-11m_ERA5_GEM5_CLASS_NV_NA_newP3-SCPF_SN8_20yrs/Samples/NAM-11m_ERA5_GEM5_CLASS_NV_NA_newP3-SCPF_SN8_20yrs_{end_date.year}0*[3-5]'))\n",
    "path_sim_11km_mam = sorted(glob.glob(fr'/chinook/roberge/Output/GEM5/Olivier/NAM-11m_ERA5_GEM50_PCPTYPEnil/Samples/NAM-11m_ERA5_GEM50_PCPTYPEnil_{end_date.year}0*[3-5]'))\n",
    "# /chinook/roberge/Output/GEM5/Olivier/NAM-11m_ERA5_GEM50_PCPTYPEnil/Samples/NAM-11m_ERA5_GEM50_PCPTYPEnil\n",
    "\n",
    "# path_sim_2p5km_mam = sorted(glob.glob(fr'/pampa/roberge/Output/GEM5/Cascades_CORDEX/CLASS/Safe_versions/Spinup/ECan_2.5km_NAM11mP3_newP3_CLASS_DEEPoff_SHALon/Samples/ECan_2.5km_NAM11mP3_newP3_CLASS_DEEPoff_SHALon_{end_date.year}0*[3-5]'))\n",
    "path_sim_2p5km_mam = sorted(glob.glob(fr'/chinook/roberge/Output/GEM5/Olivier/ECan_2.5km_NAM11mP3_GEM50_PCPTYPEnil/Samples/ECan_2.5km_NAM11mP3_GEM50_PCPTYPEnil_{end_date.year}0*[3-5]'))\n",
    "\n",
    "\n",
    "season_path = {'ON':{'daymet_tt':path_daymet_tt_on,\n",
    "                     'daymet_pr':path_daymet_pr_on,\n",
    "                     '11km':path_sim_11km_on,\n",
    "                     '2p5km':path_sim_2p5km_on},\n",
    "               'DJF':{'daymet_tt':path_daymet_tt_djf,\n",
    "                     'daymet_pr':path_daymet_pr_djf,\n",
    "                     '11km':path_sim_11km_djf,\n",
    "                     '2p5km':path_sim_2p5km_djf},\n",
    "               'MAM':{'daymet_tt':path_daymet_tt_mam,\n",
    "                     'daymet_pr':path_daymet_pr_mam,\n",
    "                     '11km':path_sim_11km_mam,\n",
    "                     '2p5km':path_sim_2p5km_mam}}\n",
    "\n",
    "# image output dir\n",
    "image_output_dir = \"/upslope/chalifour/projet_maitrise/fig/map_season\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Domain\n",
    "xll, yll = m.transform_point(lonE2p5[0, 0], latE2p5[0, 0], ccrs.PlateCarree())\n",
    "xur, yur = m.transform_point(lonE2p5[-1, -1], latE2p5[-1, -1], ccrs.PlateCarree())\n",
    "\n",
    "def get_verts_new(categ_box):\n",
    "    verts = [(categ_box['west'], categ_box['south']),\n",
    "             (categ_box['west'], categ_box['north']),\n",
    "             (categ_box['east'], categ_box['north']),\n",
    "             (categ_box['east'], categ_box['south']),\n",
    "             (0., 0.)]\n",
    "    return verts\n",
    "\n",
    "box = {'west': xll+17, 'east': xur-9, 'north':yur+4 , 'south': yll-1}\n",
    "\n",
    "vert = get_verts_new(box)\n",
    "codes = [Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY, ]\n",
    "\n",
    "path_small = Path(vert, codes)\n",
    "patch_small = patches.PathPatch(path_small, facecolor='none', ec=\"black\", lw=2, ls='--',\n",
    "                                        zorder=99999999, label='Studied domain', transform=ccrs.PlateCarree())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "path_sim_11km = path_sim_11km_on+path_sim_11km_djf+path_sim_11km_mam\n",
    "\n",
    "path_sim_2p5km = path_sim_2p5km_on+path_sim_2p5km_djf+path_sim_2p5km_mam\n",
    "\n",
    "path_saving='/upslope/chalifour/projet_maitrise/data_simulation_monthly'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "var_list_simulation = ['PR','TT','UU','VV']\n",
    "# var_list_simulation = []\n",
    "get_data = False\n",
    "# get_data = True\n",
    "\n",
    "if get_data:\n",
    "    for idx in range(len(timerange_month.month)-1):\n",
    "\n",
    "        list_month_tt_2p5km=[]\n",
    "        list_month_pr_2p5km=[]\n",
    "        list_month_tt_11km=[]\n",
    "        list_month_pr_11km=[]\n",
    "        list_month_uu_2p5km=[]\n",
    "        list_month_uu_11km=[]\n",
    "        list_month_vv_2p5km=[]\n",
    "        list_month_vv_11km=[]\n",
    "        print(f'Getting {timerange_month[idx].year}-{timerange_month[idx].month} ')\n",
    "\n",
    "        timerange_hour = pd.date_range(timerange_month[idx].strftime('%Y-%m'),timerange_month[idx+1].strftime('%Y-%m'),freq='1h')\n",
    "\n",
    "        timerange_hour = timerange_hour[timerange_hour.month == timerange_month[idx].month]\n",
    "\n",
    "        timerange_hour_datev = []\n",
    "\n",
    "        for date_h in timerange_hour:\n",
    "            timerange_hour_datev.append(rpn_chris.date_to_datev(date_h))\n",
    "\n",
    "\n",
    "        # path_11km = glob.glob(path_sim_11km[idx]+'/*m*')\n",
    "\n",
    "        # fid_11km = rmn.fstopenall(path_11km,rmn.FST_RO)\n",
    "        #\n",
    "        # for j,phase in enumerate(var_list_simulation):\n",
    "        #     print(f'getting {phase} 11km')\n",
    "        #     for hidx,datev in enumerate(timerange_hour_datev):\n",
    "        #         if hidx == 0:\n",
    "        #             rec_11km = rmn.fstlir(fid_11km, nomvar=phase, datev=timerange_hour_datev[1])\n",
    "        #             mygrid_11km = rmn.readGrid(fid_11km,rec_11km)              # Get the grid information for the (LAM) Grid -- Reads the tictac's\n",
    "        #             latlondict_11km = rmn.gdll(mygrid_11km)               # Create 2-D lat and lon fields from the grid information\n",
    "        #             lat_var_11km = latlondict_11km['lat']                     # Assign 'lat' to 2-D latitude field\n",
    "        #             lon_var_11km = latlondict_11km['lon']\n",
    "        #             # np.save(path_saving+f\"/11km/lon.npy\",np.array(lon_var_11km))\n",
    "        #\n",
    "        #             # np.save(path_saving+f\"/11km/lat.npy\",np.array(lat_var_11km))\n",
    "        #             if phase == 'TT':\n",
    "        #                 list_month_tt_11km.append(np.full(np.shape(lon_var_11km),np.nan))\n",
    "        #             elif phase == 'UU':\n",
    "        #                 list_month_uu_11km.append(np.full(np.shape(lon_var_11km),np.nan))\n",
    "        #             elif phase == 'VV':\n",
    "        #                 list_month_vv_11km.append(np.full(np.shape(lon_var_11km),np.nan))\n",
    "        #             else:\n",
    "        #                 list_month_pr_11km.append(np.full(np.shape(lon_var_11km),np.nan))\n",
    "        #\n",
    "        #\n",
    "        #         else:\n",
    "        #             # key1 = rmn.fstinf(fid, nomvar=phase)\n",
    "        #             rec_11km = rmn.fstlir(fid_11km, nomvar=phase, datev=datev)\n",
    "        #\n",
    "        #             mygrid_11km = rmn.readGrid(fid_11km,rec_11km)              # Get the grid information for the (LAM) Grid -- Reads the tictac's\n",
    "        #             latlondict_11km = rmn.gdll(mygrid_11km)               # Create 2-D lat and lon fields from the grid information\n",
    "        #             lat_var_11km = latlondict_11km['lat']                     # Assign 'lat' to 2-D latitude field\n",
    "        #             lon_var_11km = latlondict_11km['lon']\n",
    "        #             array_11km = rec_11km['d']\n",
    "        #\n",
    "        #             if phase == 'TT':\n",
    "        #                 list_month_tt_11km.append(array_11km)\n",
    "        #\n",
    "        #             elif phase == 'UU':\n",
    "        #                 list_month_uu_11km.append(array_11km*0.514444)\n",
    "        #             elif phase == 'VV':\n",
    "        #                 list_month_vv_11km.append(array_11km*0.514444)\n",
    "        #             else:\n",
    "        #                 array_11km = array_11km * 1000 * 3600\n",
    "        #\n",
    "        #                 array_11km[array_11km <= 0.1] = 0\n",
    "        #                 list_month_pr_11km.append(array_11km)\n",
    "        #\n",
    "        #\n",
    "        # # np.save(path_saving+f\"/11km/TT_{timerange_month[idx].year}_{timerange_month[idx].month}.npy\",np.array(list_month_tt_11km))\n",
    "        # #\n",
    "        # # np.save(path_saving+f\"/11km/PR_{timerange_month[idx].year}_{timerange_month[idx].month}.npy\",np.array(list_month_pr_11km))\n",
    "        # print()\n",
    "        # tt_11km = xr.DataArray(data=list_month_tt_11km,dims=['time',\"x\", \"y\"],coords=dict(lon=([\"x\", \"y\"], lon_var_11km),lat=([\"x\", \"y\"], lat_var_11km),time=timerange_hour),)\n",
    "        # pr_11km = xr.DataArray(data=list_month_pr_11km,dims=['time',\"x\", \"y\"],coords=dict(lon=([\"x\", \"y\"], lon_var_11km),lat=([\"x\", \"y\"], lat_var_11km),time=timerange_hour))\n",
    "        # uu_11km = xr.DataArray(data=list_month_uu_11km,dims=['time',\"x\", \"y\"],coords=dict(lon=([\"x\", \"y\"], lon_var_11km),lat=([\"x\", \"y\"], lat_var_11km),time=timerange_hour))\n",
    "        # vv_11km = xr.DataArray(data=list_month_vv_11km,dims=['time',\"x\", \"y\"],coords=dict(lon=([\"x\", \"y\"], lon_var_11km),lat=([\"x\", \"y\"], lat_var_11km),time=timerange_hour))\n",
    "        #\n",
    "        # with open(path_saving+f\"/11km_P3/TT_{timerange_month[idx].year}_{timerange_month[idx].month}.pickle\",\n",
    "        #           'wb') as f:\n",
    "        #     pickle.dump(tt_11km, f)\n",
    "        # tt_11km=[]\n",
    "        #\n",
    "        # with open(path_saving+f\"/11km_P3/UU_{timerange_month[idx].year}_{timerange_month[idx].month}.pickle\",\n",
    "        #           'wb') as f:\n",
    "        #     pickle.dump(uu_11km, f)\n",
    "        # uu_11km=[]\n",
    "        #\n",
    "        # with open(path_saving+f\"/11km_P3/VV_{timerange_month[idx].year}_{timerange_month[idx].month}.pickle\",\n",
    "        #           'wb') as f:\n",
    "        #     pickle.dump(vv_11km, f)\n",
    "        # vv_11km=[]\n",
    "        # with open(path_saving+f\"/11km_P3/PR_{timerange_month[idx].year}_{timerange_month[idx].month}.pickle\",\n",
    "        #           'wb') as f:\n",
    "        #     pickle.dump(pr_11km, f)\n",
    "        # #\n",
    "        # pr_11km=[]\n",
    "        #\n",
    "        # rmn.fstcloseall(fid_11km)\n",
    "\n",
    "\n",
    "\n",
    "        fid_2p5km = rmn.fstopenall(path_sim_2p5km[idx]+'/*m*',rmn.FST_RO)\n",
    "        for j,phase in enumerate(var_list_simulation):\n",
    "            print(f'getting {phase} 2.5km')\n",
    "            for hidx,datev in enumerate(timerange_hour_datev):\n",
    "                if hidx == 0:\n",
    "                    rec_2p5km = rmn.fstlir(fid_2p5km, nomvar=phase, datev=timerange_hour_datev[1])\n",
    "                    mygrid_2p5km = rmn.readGrid(fid_2p5km,rec_2p5km)              # Get the grid information for the (LAM) Grid -- Reads the tictac's\n",
    "                    latlondict_2p5km = rmn.gdll(mygrid_2p5km)               # Create 2-D lat and lon fields from the grid information\n",
    "                    lat_var_2p5km = latlondict_2p5km['lat']                     # Assign 'lat' to 2-D latitude field\n",
    "                    lon_var_2p5km = latlondict_2p5km['lon']\n",
    "                    # np.save(path_saving+f\"/2p5km/lon.npy\",np.array(lon_var_2p5km))\n",
    "\n",
    "                    # np.save(path_saving+f\"/2p5km/lat.npy\",np.array(lat_var_2p5km))\n",
    "\n",
    "                    if phase == 'TT':\n",
    "                        list_month_tt_2p5km.append(np.full(np.shape(lon_var_2p5km),np.nan))\n",
    "                    elif phase == 'UU':\n",
    "                        list_month_uu_2p5km.append(np.full(np.shape(lon_var_2p5km),np.nan))\n",
    "                    elif phase == 'VV':\n",
    "                        list_month_vv_2p5km.append(np.full(np.shape(lon_var_2p5km),np.nan))\n",
    "\n",
    "                    else:\n",
    "                        list_month_pr_2p5km.append(np.full(np.shape(lon_var_2p5km),np.nan))\n",
    "\n",
    "\n",
    "                else:\n",
    "                    rec_2p5km = rmn.fstlir(fid_2p5km, nomvar=phase, datev=datev)\n",
    "                    mygrid_2p5km = rmn.readGrid(fid_2p5km,rec_2p5km)              # Get the grid information for the (LAM) Grid -- Reads the tictac's\n",
    "                    latlondict_2p5km = rmn.gdll(mygrid_2p5km)               # Create 2-D lat and lon fields from the grid information\n",
    "                    lat_var_2p5km = latlondict_2p5km['lat']                     # Assign 'lat' to 2-D latitude field\n",
    "                    lon_var_2p5km = latlondict_2p5km['lon']\n",
    "                    array_2p5km = rec_2p5km['d']\n",
    "\n",
    "                    if phase == 'TT':\n",
    "                        list_month_tt_2p5km.append(array_2p5km)\n",
    "                    elif phase == 'UU':\n",
    "                        list_month_uu_2p5km.append(array_2p5km*0.514444)\n",
    "                    elif phase == 'VV':\n",
    "                        list_month_vv_2p5km.append(array_2p5km*0.514444)\n",
    "                    else:\n",
    "                        array_2p5km = array_2p5km* 1000* 3600\n",
    "                        array_2p5km[array_2p5km <= 0.1] = 0\n",
    "                        list_month_pr_2p5km.append(array_2p5km)\n",
    "\n",
    "\n",
    "\n",
    "        tt_2p5km = xr.DataArray(data=list_month_tt_2p5km,dims=['time',\"x\", \"y\"],coords=dict(lon=([\"x\", \"y\"], lon_var_2p5km),lat=([\"x\", \"y\"], lat_var_2p5km),time=timerange_hour))\n",
    "        uu_2p5km = xr.DataArray(data=list_month_uu_2p5km,dims=['time',\"x\", \"y\"],coords=dict(lon=([\"x\", \"y\"], lon_var_2p5km),lat=([\"x\", \"y\"], lat_var_2p5km),time=timerange_hour))\n",
    "\n",
    "        vv_2p5km = xr.DataArray(data=list_month_vv_2p5km,dims=['time',\"x\", \"y\"],coords=dict(lon=([\"x\", \"y\"], lon_var_2p5km),lat=([\"x\", \"y\"], lat_var_2p5km),time=timerange_hour))\n",
    "\n",
    "        with open(path_saving+f\"/2p5km_P3/TT_{timerange_month[idx].year}_{timerange_month[idx].month}.pickle\",\n",
    "                  'wb') as f:\n",
    "            pickle.dump(tt_2p5km, f)\n",
    "        tt_2p5km = []\n",
    "\n",
    "        with open(path_saving+f\"/2p5km_P3/UU_{timerange_month[idx].year}_{timerange_month[idx].month}.pickle\",\n",
    "                  'wb') as f:\n",
    "            pickle.dump(uu_2p5km, f)\n",
    "        uu_2p5km=[]\n",
    "\n",
    "        with open(path_saving+f\"/2p5km_P3/VV_{timerange_month[idx].year}_{timerange_month[idx].month}.pickle\",\n",
    "                  'wb') as f:\n",
    "            pickle.dump(vv_2p5km, f)\n",
    "        vv_2p5km=[]\n",
    "        # np.save(path_saving+f\"/2p5km/TT_{timerange_month[idx].year}_{timerange_month[idx].month}.npy\",np.array(list_month_tt_2p5km))\n",
    "        pr_2p5km = xr.DataArray(data=list_month_pr_2p5km,dims=['time',\"x\", \"y\"],coords=dict(lon=([\"x\", \"y\"], lon_var_2p5km),lat=([\"x\", \"y\"], lat_var_2p5km),time=timerange_hour))\n",
    "        #\n",
    "        with open(path_saving+f\"/2p5km_P3/PR_{timerange_month[idx].year}_{timerange_month[idx].month}.pickle\",\n",
    "                  'wb') as f:\n",
    "            pickle.dump(pr_2p5km, f)\n",
    "        # np.save(path_saving+f\"/2p5km/PR_{timerange_month[idx].year}_{timerange_month[idx].month}.npy\",np.array(list_month_pr_2p5km))\n",
    "        pr_2p5km=[]\n",
    "\n",
    "        rmn.fstcloseall(fid_2p5km)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get data to plot\n",
    "## Daymet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Daymet\n"
     ]
    }
   ],
   "source": [
    "print('Data Daymet')\n",
    "# daymet_tt = xr.open_mfdataset(path_daymet_tt_on+path_daymet_tt_djf+path_daymet_tt_mam, combine='by_coords', concat_dim=\"time\")\n",
    "# daymet_pr = xr.open_mfdataset(path_daymet_pr_on+path_daymet_pr_djf+path_daymet_pr_mam, combine='by_coords', concat_dim=\"time\")\n",
    "\n",
    "# print('Data Daymet DJF')\n",
    "# daymet_tt_djf = xr.open_mfdataset(path_daymet_tt_djf, combine='by_coords', concat_dim=\"time\")\n",
    "# daymet_pr_djf = xr.open_mfdataset(path_daymet_pr_djf, combine='by_coords', concat_dim=\"time\")\n",
    "\n",
    "# print('Data Daymet MAM')\n",
    "# daymet_tt_mam = xr.open_mfdataset(path_daymet_tt_mam, combine='by_coords', concat_dim=\"time\")\n",
    "# daymet_pr_mam = xr.open_mfdataset(path_daymet_pr_mam, combine='by_coords', concat_dim=\"time\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/tavg/lc/nc4/2021/10/daymet_1km_v4r1_tavg_lc_202110_d.nc4\n",
      "Treating tavg\n",
      "-6.430000305175781\n",
      "19.415000915527344\n",
      "/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/tavg/lc/nc4/2021/11/daymet_1km_v4r1_tavg_lc_202111_d.nc4\n",
      "-16.744998931884766\n",
      "12.135000228881836\n",
      "/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/tavg/lc/nc4/2021/12/daymet_1km_v4r1_tavg_lc_202112_d.nc4\n",
      "-32.96500015258789\n",
      "10.809999465942383\n",
      "/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/tavg/lc/nc4/2022/01/daymet_1km_v4r1_tavg_lc_202201_d.nc4\n",
      "-35.220001220703125\n",
      "5.180000305175781\n",
      "/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/tavg/lc/nc4/2022/02/daymet_1km_v4r1_tavg_lc_202202_d.nc4\n",
      "-38.48500061035156\n",
      "10.11500072479248\n",
      "/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/tavg/lc/nc4/2022/03/daymet_1km_v4r1_tavg_lc_202203_d.nc4\n",
      "-35.70000076293945\n",
      "11.984999656677246\n",
      "/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/tavg/lc/nc4/2022/04/daymet_1km_v4r1_tavg_lc_202204_d.nc4\n",
      "-16.899999618530273\n",
      "15.005000114440918\n",
      "/home/archive/OBSERVATIONS/Daymet_1km_v4r1/daily/tavg/lc/nc4/2022/05/daymet_1km_v4r1_tavg_lc_202205_d.nc4\n",
      "-10.899999618530273\n",
      "25.545001983642578\n"
     ]
    }
   ],
   "source": [
    "# cut to domain\n",
    "\n",
    "get_daymet = True\n",
    "# get_daymet = False\n",
    "\n",
    "# day_tt = xr.concat([daymet_tt_on,daymet_tt_djf,daymet_tt_mam],dim='time').tavg\n",
    "# daymet_tt_on,daymet_tt_djf,daymet_tt_mam = [],[],[]\n",
    "# day_pr = xr.concat([daymet_pr_on,daymet_pr_djf,daymet_pr_mam],dim='time').prcp\n",
    "# daymet_pr_on,daymet_pr_djf,daymet_pr_mam = [],[],[]\n",
    "list_var = ['tavg']\n",
    "mask_day = 0\n",
    "if get_daymet:\n",
    "    list_path_day = [path_daymet_tt_on+path_daymet_tt_djf+path_daymet_tt_mam,path_daymet_pr_on+path_daymet_pr_djf+path_daymet_pr_mam]\n",
    "    for i,var in enumerate(list_var):\n",
    "        day_path = list_path_day[i]\n",
    "        for j,path in enumerate(day_path):\n",
    "            print(path)\n",
    "            if i == 0 and j ==0:\n",
    "                day_var = xr.open_mfdataset(path)[var]\n",
    "                print(f'Treating {var}')\n",
    "                grid_lonlat = m.transform_points(ccrs.PlateCarree(),day_var.lon.values,day_var.lat.values)[:,:,0:2]\n",
    "\n",
    "\n",
    "                xll, yll = m.transform_point(lonE2p5[0, 0], latE2p5[0, 0], ccrs.PlateCarree())\n",
    "                xur, yur = m.transform_point(lonE2p5[-1, -1], latE2p5[-1, -1], ccrs.PlateCarree())\n",
    "\n",
    "                box = {'west': xll+ 17, 'east': xur- 9, 'north':yur- 1 , 'south': yll+ 4}\n",
    "\n",
    "                vert = get_verts_new(box)\n",
    "                codes = [Path.MOVETO, Path.LINETO, Path.LINETO, Path.LINETO, Path.CLOSEPOLY, ]\n",
    "                path_small = Path(vert, codes)\n",
    "\n",
    "                shape_grid = np.shape(grid_lonlat)\n",
    "                point_in_domain = path_small.contains_points(grid_lonlat.reshape(shape_grid[0] * shape_grid[1], 2),radius=0).reshape(shape_grid[0], shape_grid[1])\n",
    "\n",
    "                mask_day = point_in_domain\n",
    "                day_var.load()\n",
    "                data_day_mask = day_var.where(mask_day).dropna(dim='x',how=\"all\").dropna(dim='y',how=\"all\")\n",
    "\n",
    "            else:\n",
    "                day_var = xr.open_mfdataset(path, combine='by_coords', concat_dim=\"time\")[list_var[i]]\n",
    "                day_var.load()\n",
    "                data_day_mask = day_var.where(mask_day).dropna(dim='x',how=\"all\").dropna(dim='y',how=\"all\")\n",
    "\n",
    "\n",
    "            print(data_day_mask.min().values)\n",
    "            print(data_day_mask.max().values)\n",
    "            data_day_mask.to_netcdf(path_saving+f\"/daymet/{var}_{path[-12:-6]}.nc\")\n",
    "\n",
    "    # daymet_tt_on_mean = daymet_tt_on\n",
    "    # daymet_tt_djf_mean = daymet_tt_djf\n",
    "    # daymet_tt_mam_mean = daymet_tt_mam\n",
    "    #\n",
    "    #\n",
    "    # daymet_pr_on_sum = daymet_pr_on\n",
    "    # daymet_pr_djf_sum = daymet_pr_djf\n",
    "    # daymet_pr_mam_sum = daymet_pr_mam\n",
    "\n",
    "\n",
    "    # print('Treating TT')\n",
    "    #\n",
    "    # daymet_tt_on_mean = ma.masked_array(daymet_tt_on_mean['tavg'].values, mask)\n",
    "    #\n",
    "    # xrdata_tt_on = xr.DataArray(data=daymet_tt_on_mean['tavg'].values,\n",
    "    #                                  dims=[\"x\", \"y\", ],\n",
    "    #                                  coords=dict(lon=([\"x\", \"y\"], daymet_tt_on.lon.values),\n",
    "    #                                              lat=([\"x\", \"y\"], daymet_tt_on.lat.values),\n",
    "    #                                              ))\n",
    "    # daymet_tt_on_mean.to_netcdf(path_saving+f\"/daymet/TT_on_{begin_date.year}.nc\")\n",
    "    #\n",
    "    # daymet_tt_djf_mean = ma.masked_array(daymet_tt_djf_mean['tavg'].values, mask)\n",
    "    # xrdata_tt_djf = xr.DataArray(data=daymet_tt_djf_mean['tavg'].values,\n",
    "    #                                  dims=[\"x\", \"y\", ],\n",
    "    #                                  coords=dict(lon=([\"x\", \"y\"], daymet_tt_on.lon.values),\n",
    "    #                                              lat=([\"x\", \"y\"], daymet_tt_on.lat.values),\n",
    "    #                                              ))\n",
    "    # daymet_tt_djf_mean.to_netcdf(path_saving+f\"/daymet/TT_djf_{begin_date.year}.nc\")\n",
    "    #\n",
    "    # daymet_tt_mam_mean = ma.masked_array(daymet_tt_mam_mean['tavg'].values, mask)\n",
    "    # xrdata_tt_mam = xr.DataArray(data=daymet_tt_mam_mean['tavg'].values,\n",
    "    #                                  dims=[\"x\", \"y\", ],\n",
    "    #                                  coords=dict(lon=([\"x\", \"y\"], daymet_tt_on.lon.values),\n",
    "    #                                              lat=([\"x\", \"y\"], daymet_tt_on.lat.values),\n",
    "    #                                              ))\n",
    "    # daymet_tt_mam_mean.to_netcdf(path_saving+f\"/daymet/TT_mam_{begin_date.year}.nc\")\n",
    "\n",
    "    # print('Treating PR')\n",
    "    # daymet_pr_on_sum = ma.masked_array(daymet_pr_on_sum['prcp'].values, mask)\n",
    "    # xrdata_pr_on = xr.DataArray(data=daymet_pr_on_sum['prcp'].values,\n",
    "    #                                  dims=[\"x\", \"y\", ],\n",
    "    #                                  coords=dict(lon=([\"x\", \"y\"], daymet_tt_on.lon.values),\n",
    "    #                                              lat=([\"x\", \"y\"], daymet_tt_on.lat.values),\n",
    "    #                                              ))\n",
    "    # daymet_pr_on_sum.to_netcdf(path_saving+f\"/daymet/PR_on_{begin_date.year}.nc\")\n",
    "\n",
    "    # daymet_pr_djf_sum = ma.masked_array(daymet_pr_djf_sum['prcp'].values, mask)\n",
    "    # xrdata_pr_djf = xr.DataArray(data=daymet_pr_djf_sum['prcp'].values,\n",
    "    #                                  dims=[\"x\", \"y\", ],\n",
    "    #                                  coords=dict(lon=([\"x\", \"y\"], daymet_tt_on.lon.values),\n",
    "    #                                              lat=([\"x\", \"y\"], daymet_tt_on.lat.values),\n",
    "    #                                              ))\n",
    "    # daymet_pr_djf_sum.to_netcdf(path_saving+f\"/daymet/PR_djf_{begin_date.year}.nc\")\n",
    "    #\n",
    "    # daymet_pr_mam_sum = ma.masked_array(daymet_pr_mam_sum['prcp'].values, mask)\n",
    "    # xrdata_pr_mam = xr.DataArray(data=daymet_pr_mam_sum['prcp'].values,\n",
    "    #                                  dims=[\"x\", \"y\", ],\n",
    "    #                                  coords=dict(lon=([\"x\", \"y\"], daymet_tt_on.lon.values),\n",
    "    #                                              lat=([\"x\", \"y\"], daymet_tt_on.lat.values),\n",
    "    #                                              ))\n",
    "    # daymet_pr_mam_sum.to_netcdf(path_saving+f\"/daymet/PR_mam_{begin_date.year}.nc\")\n",
    "\n",
    "else:\n",
    "    xrdata_tt_on = xr.open_mfdataset(path_saving+f\"/daymet/TT_on_{begin_date.year}.nc\")\n",
    "    xrdata_tt_djf = xr.open_mfdataset(path_saving+f\"/daymet/TT_djf_{begin_date.year}.nc\")\n",
    "    xrdata_tt_mam = xr.open_mfdataset(path_saving+f\"/daymet/TT_mam_{begin_date.year}.nc\")\n",
    "\n",
    "    xrdata_pr_on = xr.open_mfdataset(path_saving+f\"/daymet/PR_on_{begin_date.year}.nc\")\n",
    "    xrdata_pr_djf = xr.open_mfdataset(path_saving+f\"/daymet/PR_djf_{begin_date.year}.nc\")\n",
    "    xrdata_pr_mam = xr.open_mfdataset(path_saving+f\"/daymet/PR_mam_{begin_date.year}.nc\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## 11km"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2021-10\n",
      "Loading 2021-11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-1224646912d3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'/upslope/chalifour/projet_maitrise/data_simulation_monthly/11km_P3/TT_{month.year}_{month.month}.pickle'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpickle_file_tt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mtt_11km_month\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpickle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpickle_file_tt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         \u001B[0mmax_tt_11km_daily\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mtt_11km_month\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"1D\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mmin_tt_11km_daily\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mtt_11km_month\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"1D\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mmean_tt_11km_daily\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmax_tt_11km_daily\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mmin_tt_11km_daily\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/common.py\u001B[0m in \u001B[0;36mwrapped_func\u001B[0;34m(self, dim, axis, skipna, **kwargs)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m             \u001B[0;32mdef\u001B[0m \u001B[0mwrapped_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskipna\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 56\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduce\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskipna\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mskipna\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/groupby.py\u001B[0m in \u001B[0;36mreduce\u001B[0;34m(self, func, dim, axis, keep_attrs, shortcut, **kwargs)\u001B[0m\n\u001B[1;32m    875\u001B[0m         \u001B[0mcheck_reduce_dims\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdims\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    876\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 877\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreduce_array\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshortcut\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshortcut\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    878\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/resample.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, func, shortcut, args, **kwargs)\u001B[0m\n\u001B[1;32m    219\u001B[0m         \u001B[0;31m# TODO: the argument order for Resample doesn't match that for its parent,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0;31m# GroupBy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 221\u001B[0;31m         \u001B[0mcombined\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshortcut\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshortcut\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[0;31m# If the aggregation function didn't drop the original resampling\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/groupby.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, func, shortcut, args, **kwargs)\u001B[0m\n\u001B[1;32m    792\u001B[0m         \u001B[0mgrouped\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iter_grouped_shortcut\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mshortcut\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iter_grouped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    793\u001B[0m         \u001B[0mapplied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmaybe_wrap_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0marr\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgrouped\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 794\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_combine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mapplied\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshortcut\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshortcut\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    795\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    796\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshortcut\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/groupby.py\u001B[0m in \u001B[0;36m_combine\u001B[0;34m(self, applied, shortcut)\u001B[0m\n\u001B[1;32m    814\u001B[0m         \u001B[0mcoord\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpositions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_infer_concat_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mapplied_example\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    815\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mshortcut\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 816\u001B[0;31m             \u001B[0mcombined\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_concat_shortcut\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mapplied\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpositions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    817\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    818\u001B[0m             \u001B[0mcombined\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mapplied\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/groupby.py\u001B[0m in \u001B[0;36m_concat_shortcut\u001B[0;34m(self, applied, dim, positions)\u001B[0m\n\u001B[1;32m    731\u001B[0m         \u001B[0;31m# faster alternatives (e.g., doing the grouped aggregation in a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    732\u001B[0m         \u001B[0;31m# compiled language)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 733\u001B[0;31m         \u001B[0mstacked\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVariable\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mapplied\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshortcut\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    734\u001B[0m         \u001B[0mreordered\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_maybe_reorder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstacked\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpositions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    735\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_replace_maybe_drop_dims\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreordered\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/variable.py\u001B[0m in \u001B[0;36mconcat\u001B[0;34m(cls, variables, dim, positions, shortcut, combine_attrs)\u001B[0m\n\u001B[1;32m   1811\u001B[0m         \u001B[0;31m# can't do this lazily: we need to loop through variables at least\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1812\u001B[0m         \u001B[0;31m# twice\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1813\u001B[0;31m         \u001B[0mvariables\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvariables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1814\u001B[0m         \u001B[0mfirst_var\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvariables\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1815\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/groupby.py\u001B[0m in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    791\u001B[0m         \"\"\"\n\u001B[1;32m    792\u001B[0m         \u001B[0mgrouped\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iter_grouped_shortcut\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mshortcut\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iter_grouped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 793\u001B[0;31m         \u001B[0mapplied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmaybe_wrap_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0marr\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgrouped\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    794\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_combine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mapplied\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshortcut\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshortcut\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    795\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/groupby.py\u001B[0m in \u001B[0;36mreduce_array\u001B[0;34m(ar)\u001B[0m\n\u001B[1;32m    871\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    872\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mreduce_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 873\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mar\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreduce\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeep_attrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkeep_attrs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    874\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    875\u001B[0m         \u001B[0mcheck_reduce_dims\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdims\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/variable.py\u001B[0m in \u001B[0;36mreduce\u001B[0;34m(self, func, dim, axis, keep_attrs, keepdims, **kwargs)\u001B[0m\n\u001B[1;32m   1721\u001B[0m             )\n\u001B[1;32m   1722\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0maxis\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1723\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1724\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1725\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/duck_array_ops.py\u001B[0m in \u001B[0;36mf\u001B[0;34m(values, axis, skipna, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mwarnings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcatch_warnings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    361\u001B[0m                 \u001B[0mwarnings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilterwarnings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"ignore\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"All-NaN slice encountered\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 362\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    363\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    364\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_duck_dask_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/nanops.py\u001B[0m in \u001B[0;36mnanmax\u001B[0;34m(a, axis, out)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m     \u001B[0mmodule\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdask_array\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdask_array_type\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mnputils\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 91\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnanmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     92\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/sca/compilers_and_tools/python/miniconda3/envs/base_plus/lib/python3.8/site-packages/xarray/core/nputils.py\u001B[0m in \u001B[0;36mf\u001B[0;34m(values, axis, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m             \u001B[0;31m# bottleneck does not take care dtype, min_count\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"dtype\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbn_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnpmodule\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "list_tt_11km=[]\n",
    "list_pr_11km=[]\n",
    "for month in timerange_month[:-1]:\n",
    "    print(f'Loading {month.year}-{month.month}')\n",
    "    with open(f'/upslope/chalifour/projet_maitrise/data_simulation_monthly/11km_P3/TT_{month.year}_{month.month}.pickle', 'rb') as pickle_file_tt:\n",
    "        tt_11km_month = pickle.load(pickle_file_tt)\n",
    "        max_tt_11km_daily= tt_11km_month.resample(time=\"1D\").max()\n",
    "        min_tt_11km_daily= tt_11km_month.resample(time=\"1D\").min()\n",
    "        mean_tt_11km_daily = (max_tt_11km_daily+min_tt_11km_daily)/2\n",
    "        list_tt_11km.append(mean_tt_11km_daily)\n",
    "\n",
    "    with open(f'/upslope/chalifour/projet_maitrise/data_simulation_monthly/11km_P3/PR_{month.year}_{month.month}.pickle', 'rb') as pickle_file_pr:\n",
    "        pr_11km_month = pickle.load(pickle_file_pr)\n",
    "        sum_pr_11km_daily = pr_11km_month.resample(time=\"1D\").sum()\n",
    "        list_pr_11km.append(sum_pr_11km_daily)\n",
    "\n",
    "\n",
    "tt_11km = xr.concat(list_tt_11km,dim='time')\n",
    "pr_11km = xr.concat(list_pr_11km,dim='time')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "dict_season_tt_11km={}\n",
    "dict_season_pr_11km={}\n",
    "for month_id, ds_month in tt_11km.groupby('time.season'):\n",
    "    ds_month_complete = ds_month.mean(dim='time',skipna=True)\n",
    "\n",
    "    # xl = m.transform_points(ccrs.PlateCarree(),ds_month_complete.lon.values-360, ds_month_complete.lat.values)\n",
    "    #\n",
    "    # lon_m_ds_month_compl = xl[:,:,0]\n",
    "    # lat_m_ds_month_compl = xl[:,:,1]\n",
    "    #\n",
    "    # grid = np.stack((lon_m_ds_month_compl, lat_m_ds_month_compl), axis=-1)\n",
    "    # shape_grid = np.shape(grid)\n",
    "    #\n",
    "    # point_in_domain = path_small.contains_points(grid.reshape(shape_grid[0] * shape_grid[1], 2),\n",
    "    #                                              radius=1e-9).reshape(shape_grid[0], shape_grid[1])\n",
    "    #\n",
    "    # mask = np.invert(point_in_domain)\n",
    "    # lon_daymet_mask = ma.masked_array(ds_month_complete.lon.values, mask)\n",
    "    # lat_daymet_mask = ma.masked_array(ds_month_complete.lat.values, mask)\n",
    "\n",
    "    # ds_month_season = xr.DataArray(data=ds_month_complete.values,\n",
    "    #                              dims=[\"x\", \"y\", ],\n",
    "    #                              coords=dict(lon=([\"x\", \"y\"], ds_month_complete.lon.values),\n",
    "    #                                          lat=([\"x\", \"y\"], ds_month_complete.lat.values),\n",
    "    #                                          ))\n",
    "    dict_season_tt_11km[month_id] = ds_month_complete\n",
    "\n",
    "with open(path_saving+f\"/11km_P3/TT_season_dict_{begin_date.year}.pickle\",'wb') as f:\n",
    "    pickle.dump(dict_season_tt_11km, f)\n",
    "\n",
    "for month_id, ds_month in pr_11km.groupby('time.season'):\n",
    "    ds_month_complete = ds_month.sum(dim='time',skipna=True)\n",
    "    # xl = m.transform_points(ccrs.PlateCarree(),ds_month_complete.lon.values-360, ds_month_complete.lat.values)\n",
    "    #\n",
    "    # lon_m_ds_month_compl = xl[:,:,0]\n",
    "    # lat_m_ds_month_compl = xl[:,:,1]\n",
    "    #\n",
    "    # grid = np.stack((lon_m_ds_month_compl, lat_m_ds_month_compl), axis=-1)\n",
    "    # shape_grid = np.shape(grid)\n",
    "    #\n",
    "    # point_in_domain = path_small.contains_points(grid.reshape(shape_grid[0] * shape_grid[1], 2),\n",
    "    #                                              radius=1e-9).reshape(shape_grid[0], shape_grid[1])\n",
    "    #\n",
    "    # mask = np.invert(point_in_domain)\n",
    "    # lon_daymet_mask = ma.masked_array(ds_month_complete.lon.values, mask)\n",
    "    # lat_daymet_mask = ma.masked_array(ds_month_complete.lat.values, mask)\n",
    "\n",
    "    # ds_month_season = xr.DataArray(data=ds_month_complete.values,\n",
    "    #                              dims=[\"x\", \"y\", ],\n",
    "    #                              coords=dict(lon=([\"x\", \"y\"], ds_month_complete.lon.values),\n",
    "    #                                          lat=([\"x\", \"y\"], ds_month_complete.lat.values),\n",
    "    #                                          ))\n",
    "    dict_season_pr_11km[month_id] = ds_month_complete\n",
    "with open(path_saving+f\"/11km_P3/PR_season_dict_{begin_date.year}.pickle\",'wb') as f:\n",
    "    pickle.dump(dict_season_pr_11km, f)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.5 km"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_tt_2p5km = []\n",
    "list_pr_2p5km = []\n",
    "for month in timerange_month[:-1]:\n",
    "    print(f'Loading {month.year}-{month.month}')\n",
    "    with open(f'/upslope/chalifour/projet_maitrise/data_simulation_monthly/2p5km_P3/TT_{month.year}_{month.month}.pickle',\n",
    "              'rb') as pickle_file_tt:\n",
    "        tt_2p5km_month = pickle.load(pickle_file_tt)\n",
    "        max_tt_2p5km_daily = tt_2p5km_month.resample(time=\"1D\").max()\n",
    "        min_tt_2p5km_daily = tt_2p5km_month.resample(time=\"1D\").min()\n",
    "        mean_tt_2p5km_daily = (max_tt_2p5km_daily + min_tt_2p5km_daily) / 2\n",
    "        list_tt_2p5km.append(mean_tt_2p5km_daily)\n",
    "\n",
    "    with open(f'/upslope/chalifour/projet_maitrise/data_simulation_monthly/2p5km_P3/PR_{month.year}_{month.month}.pickle',\n",
    "              'rb') as pickle_file_pr:\n",
    "        tt_2p5km_month = pickle.load(pickle_file_pr)\n",
    "        sum_pr_2p5km_daily = tt_2p5km_month.resample(time=\"1D\").sum()\n",
    "        list_pr_2p5km.append(sum_pr_2p5km_daily)\n",
    "\n",
    "tt_2p5km = xr.concat(list_tt_2p5km, dim='time')\n",
    "\n",
    "pr_2p5km = xr.concat(list_pr_2p5km, dim='time')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "dict_season_tt_2p5km = {}\n",
    "dict_season_pr_2p5km = {}\n",
    "\n",
    "for month_id, ds_month in tt_2p5km.groupby('time.season'):\n",
    "    ds_month_complete = ds_month.mean(dim='time',skipna=True)\n",
    "\n",
    "    # xl = m.transform_points(ccrs.PlateCarree(),ds_month_complete.lon.values-360, ds_month_complete.lat.values)\n",
    "    #\n",
    "    # lon_m_ds_month_compl = xl[:,:,0]\n",
    "    # lat_m_ds_month_compl = xl[:,:,1]\n",
    "    #\n",
    "    # grid = np.stack((lon_m_ds_month_compl, lat_m_ds_month_compl), axis=-1)\n",
    "    # shape_grid = np.shape(grid)\n",
    "    #\n",
    "    # point_in_domain = path_small.contains_points(grid.reshape(shape_grid[0] * shape_grid[1], 2),\n",
    "    #                                              radius=1e-9).reshape(shape_grid[0], shape_grid[1])\n",
    "    #\n",
    "    # mask = np.invert(point_in_domain)\n",
    "    # lon_daymet_mask = ma.masked_array(ds_month_complete.lon.values, mask)\n",
    "    # lat_daymet_mask = ma.masked_array(ds_month_complete.lat.values, mask)\n",
    "    #\n",
    "    # ds_month_season = xr.DataArray(data=ma.masked_array(ds_month_complete.values, mask),\n",
    "    #                                dims=[\"x\", \"y\", ],\n",
    "    #                                coords=dict(lon=([\"x\", \"y\"], lon_daymet_mask),\n",
    "    #                                            lat=([\"x\", \"y\"], lat_daymet_mask),\n",
    "    #                                            ))\n",
    "    dict_season_tt_2p5km[month_id] = ds_month_complete\n",
    "with open(path_saving+f\"/2p5km_P3/TT_season_dict_{begin_date.year}.pickle\",'wb') as f:\n",
    "    pickle.dump(dict_season_tt_2p5km, f)\n",
    "for month_id, ds_month in pr_2p5km.groupby('time.season'):\n",
    "    ds_month_complete = ds_month.sum(dim='time',skipna=True)\n",
    "\n",
    "    # xl = m.transform_points(ccrs.PlateCarree(),ds_month_complete.lon.values-360, ds_month_complete.lat.values)\n",
    "    #\n",
    "    # lon_m_ds_month_compl = xl[:,:,0]\n",
    "    # lat_m_ds_month_compl = xl[:,:,1]\n",
    "    #\n",
    "    # grid = np.stack((lon_m_ds_month_compl, lat_m_ds_month_compl), axis=-1)\n",
    "    # shape_grid = np.shape(grid)\n",
    "    #\n",
    "    # point_in_domain = path_small.contains_points(grid.reshape(shape_grid[0] * shape_grid[1], 2),\n",
    "    #                                              radius=1e-9).reshape(shape_grid[0], shape_grid[1])\n",
    "    #\n",
    "    # mask = np.invert(point_in_domain)\n",
    "    # lon_daymet_mask = ma.masked_array(ds_month_complete.lon.values, mask)\n",
    "    # lat_daymet_mask = ma.masked_array(ds_month_complete.lat.values, mask)\n",
    "    #\n",
    "    # ds_month_season = xr.DataArray(data=ma.masked_array(ds_month_complete.values, mask),\n",
    "    #                                dims=[\"x\", \"y\", ],\n",
    "    #                                coords=dict(lon=([\"x\", \"y\"], lon_daymet_mask),\n",
    "    #                                            lat=([\"x\", \"y\"], lat_daymet_mask),\n",
    "    #                                            ))\n",
    "    dict_season_pr_2p5km[month_id] = ds_month_complete\n",
    "with open(path_saving+f\"/2p5km_P3/PR_season_dict_{begin_date.year}.pickle\",'wb') as f:\n",
    "    pickle.dump(dict_season_pr_2p5km, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
